import sys
import Orange
import os
import subprocess
import sqlite3
import matplotlib.pyplot as plt
import pandas as pd

from typing import Dict, List
from functools import cmp_to_key
from common import filesystem

class Snapshot:
    def __init__(self, trial_id: int, targets_total: int,
                 targets_covered: int, time: int, trial_group_num: int,
                 fuzzer: str, benchmark: str, mini_benchmark: str, edges_covered: int):
        self.fuzzer =  fuzzer
        self.benchmark =  benchmark

        # fuzzbench trial id
        self.trial_id =  trial_id
        # no. of target branches
        self.targets_total =  targets_total
        # no. of discovered target branches
        self.targets_covered = targets_covered
        # time the snapshot was measured
        self.time = time
        # mini benchmark group number
        self.trial_group_num = trial_group_num
        # name of mini benchmark
        self.mini_benchmark =  mini_benchmark
        # covered branches (fuzzbench default metric)
        self.edges_covered =  edges_covered
        # rank of this snapshot (will be assigned by this script)
        self.rank = None

class Trial:
    def __init__(self, trial_id, fuzzer, benchmark, trial_group_num):
        self.trial_id = trial_id
        self.fuzzer = fuzzer
        self.benchmark = benchmark
        self.trial_group_num = trial_group_num

class ReportConfig:
    def __init__(self, sqlite_local_db_file: str):
        # path of sqlite db file generated by fuzzbench
        self.sqlite_local_db_file = sqlite_local_db_file

# report configuration
report_config: ReportConfig = None

# report output location
REPORT_DIRECTORY = "report"

# fuzzers in the given experiment
fuzzers = []

# benchmarks in the given experiment
benchmarks = []

# dictionary of mini benchmark
mini_benchmark_snapshots: Dict[str, List[Snapshot]] = {}

# fuzzbench coverage measurement snapshots
snapshots: List[Snapshot] = []

def get_mini_benchmark_key(benchmark: str, trial_group_num: int):
    return "{}_#_{}".format(benchmark, trial_group_num)

def get_db_connection():
    return sqlite3.connect(report_config.sqlite_local_db_file)

def generate_html(ranking):
    rank_table_text = "<div><table><thead><tr><th>Fuzzer</th><th>Rank</th></tr></thead><div>"
    for fuzzer, rank in ranking.items():
        rank_table_text += "<tr><td>{}</td><td>{:.2f}</td></tr>".format(fuzzer, rank)
    rank_table_text += "</table>"
    report_html = os.path.join(REPORT_DIRECTORY, 'index.html')
    html = "<style>table, th, td {border: 1px solid black;}</style>"
    html += "<h1>GreenBench - Experiment Summary</h1>"
    html += "\n<h3>Critical difference </h3>"
    html += '\n<img src="./plots/experiment_critical_difference_plot.svg"/>\n'
    html += rank_table_text
    with open(report_html, mode='wt', encoding='utf-8') as f:
        f.write(html)

def fetch_fuzzers():
    conn = get_db_connection()
    cur = conn.cursor()
    sql_query = "SELECT DISTINCT(fuzzer) as fuzzer from trial"
    for row in cur.execute(sql_query):
        fuzzers.append(row[0])
    cur.close()

def fetch_benchmarks():
    conn = get_db_connection()
    cur = conn.cursor()
    sql_query = "SELECT DISTINCT(benchmark) as benchmark from trial"
    for row in cur.execute(sql_query):
        benchmarks.append(row[0])
    cur.close()

def create_report_directory():
    filesystem.recreate_directory(REPORT_DIRECTORY)
    plots_dir = os.path.join(REPORT_DIRECTORY, "plots")
    filesystem.recreate_directory(plots_dir)

def generate_critical_difference_plot(average_ranks, num_of_benchmarks):
    image_path = os.path.join(REPORT_DIRECTORY, "plots", "experiment_critical_difference_plot.svg")
    critical_difference = Orange.evaluation.compute_CD(average_ranks.values, num_of_benchmarks)
    Orange.evaluation.graph_ranks(average_ranks.values, average_ranks.index, critical_difference)
    fig = plt.gcf()
    try:
        fig.savefig(image_path, bbox_inches="tight")
    finally:
        plt.close(fig)
    return critical_difference

def fetch_snapshots():
    conn = get_db_connection()
    cur = conn.cursor()
    trials: Dict[str, Trial] = {}
    snapshot_dict: Dict[str, Snapshot] = {}
    targets_per_campaign = {}

    # get trial info
    sql_query = 'SELECT id, fuzzer, benchmark, trial_group_num FROM trial'
    for trial_id, fuzzer, benchmark, trial_group_num in cur.execute(sql_query):
        trials[trial_id] = Trial(trial_id, fuzzer, benchmark, trial_group_num)

    # get total target edges per campaign
    sql_query = "SELECT benchmark, trial_group_num, count(*) AS total_target FROM 'target_coverage' GROUP BY benchmark, trial_group_num"
    for benchmark, trial_group_num, total_target in cur.execute(sql_query):
        mini_benchmark_key = get_mini_benchmark_key(benchmark, trial_group_num)
        targets_per_campaign[mini_benchmark_key] = total_target

    query_snapshot_str = 'SELECT trial_id, time, trial_group_num, edges_covered, targets_covered FROM snapshot order by trial_id, time'
    for trial_id, time, trial_group_num, edges_covered, targets_covered in cur.execute(query_snapshot_str):
        trial = trials[trial_id]
        mini_benchmark_key = get_mini_benchmark_key(trial.benchmark, trial_group_num)
        targets_total = targets_per_campaign[mini_benchmark_key]
        if trial_id not in snapshot_dict:
            snapshot_dict[trial_id] = Snapshot(
                trial_id, targets_total, targets_covered,
                time,  trial_group_num, trial.fuzzer,
                trial.benchmark, mini_benchmark_key, edges_covered)
        elif targets_covered > snapshot_dict[trial_id].targets_covered:
            # only replace existing snapshot data if there is better result (higher coverage than former snapshot)
            snapshot = snapshot_dict[trial_id]
            snapshot.targets_covered = targets_covered
            snapshot.edges_covered = edges_covered
            snapshot.time = time

    for snapshot in list(snapshot_dict.values()):
        snapshots.append(snapshot)
    conn.close()

def init_data():
    fetch_fuzzers()
    fetch_benchmarks()
    fetch_snapshots()

    for snapshot in snapshots:
        mini_benchmark_key = snapshot.mini_benchmark
        if snapshot.mini_benchmark not in mini_benchmark_snapshots:
            mini_benchmark_snapshots[snapshot.mini_benchmark] = []
        mini_benchmark_snapshots[mini_benchmark_key].append(snapshot)

def get_fuzzer_benchmark_key(fuzzer, benchmark):
    return fuzzer + ' ' + benchmark

def compute_avg_rank():
    def compare_micro_benchmark(a: Snapshot, b: Snapshot):
        if a.targets_covered == b.targets_covered and a.time == b.time:
            return b.edges_covered - a.edges_covered
        if a.targets_covered == b.targets_covered:
            return a.time - b.time
        return b.targets_covered - a.targets_covered

    for mini_benchmark in mini_benchmark_snapshots.keys():
        mini_benchmark_snapshots[mini_benchmark].sort(key=cmp_to_key(compare_micro_benchmark))
        prev: Snapshot = None
        cur_rank = 1
        for item in mini_benchmark_snapshots[mini_benchmark]:
            # if two fuzzers have the exact same result, then they have the same rank
            if prev is not None and item.targets_covered == prev.targets_covered and item.time == prev.time and item.edges_covered == prev.edges_covered:
                item.rank = prev.rank
            else:
                item.rank = cur_rank
                cur_rank += 1
            prev = item

    ranking_df = pd.DataFrame([snapshot.__dict__ for snapshot in snapshots])
    pivot_table = pd.pivot_table(ranking_df, index=['mini_benchmark'], columns=['fuzzer'], values='rank')
    average_ranks = pivot_table.mean().sort_values()
    average_ranks = average_ranks.rename('average rank')

    print("\nGreenBench - Fuzzer Ranking\n------")
    for fuzzer, rank in average_ranks.items():
        print('{:<20} {}'.format(fuzzer, rank))
    return average_ranks

def get_local_db_path():
    args = sys.argv[1:]
    if len(args) == 1:
        return str(args[0])
    return None

def main():
    sqlite_local_db_file = get_local_db_path()
    if sqlite_local_db_file is None:
        sys.exit("Error: please run this script followed by path of fuzzbench local.db (sqlite) file")
    global report_config
    report_config = ReportConfig(sqlite_local_db_file)

    create_report_directory()
    init_data()
    ranking = compute_avg_rank()
    generate_critical_difference_plot(ranking, len(mini_benchmark_snapshots.keys()))
    generate_html(ranking)

if __name__ == '__main__':
    sys.exit(main())
